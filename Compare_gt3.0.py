import os
import cv2
import numpy as np
import torch
import matplotlib.pyplot as plt
import albumentations as A
from albumentations.pytorch import ToTensorV2
import segmentation_models_pytorch as smp
import random

# =============================================================
# 1. ğŸ› ï¸ é…ç½®åŒºåŸŸ (è¯·ä¿®æ”¹è¿™é‡Œ!)
# =============================================================
# æ–°æ¨¡å‹çš„æƒé‡æ–‡ä»¶è·¯å¾„ (ç¡®ä¿æ˜¯é‚£ä¸ª efficientnet-b4 çš„æ¨¡å‹)
MODEL_PATH = "D:/InfSec/best_checkpoint.pth4.0.tar" 

# æ•°æ®é›†æ ¹ç›®å½•
DATA_ROOT = r"D:\InfSec\Data\recodai-luc-scientific-image-forgery-detection" 

# æµ‹è¯•å›¾ç‰‡ç›®å½• (å»ºè®®æŒ‡å‘ supplemental_images çœ‹çœ‹æ–°æ•°æ®æ•ˆæœ)
#TEST_IMG_DIR = os.path.join(DATA_ROOT, "supplemental_images") 
TEST_IMG_DIR = os.path.join(DATA_ROOT, "train_images/forged") # ä¹Ÿå¯ä»¥æµ‹åŸæ¥çš„

# æ©ç ç›®å½• (è¦å¯¹åº”ä¸Šé¢çš„å›¾ç‰‡ç›®å½•)
#MASK_DIR = os.path.join(DATA_ROOT, "supplemental_masks")
MASK_DIR = os.path.join(DATA_ROOT, "train_masks")

# æ¨ç†åˆ†è¾¨ç‡ (å¿…é¡»ä¸è®­ç»ƒæ—¶ä¸€è‡´!!)
INPUT_SIZE = 512 

DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# =============================================================
# 2. ğŸ§  æ¨¡å‹æ„å»º (å‡çº§ä¸º EfficientNet-B4)
# =============================================================
def build_model():
    print(f"ğŸ—ï¸ æ­£åœ¨æ„å»ºæ¨¡å‹: EfficientNet-B4 (è¾“å…¥åˆ†è¾¨ç‡ {INPUT_SIZE}x{INPUT_SIZE})...")
    return smp.Unet(
        encoder_name="efficientnet-b4", # âš ï¸ å¿…é¡»åŒ¹é…è®­ç»ƒæ—¶çš„ Encoder
        encoder_weights=None,           # æ¨ç†æ¨¡å¼ä¸éœ€è¦ä¸‹è½½é¢„è®­ç»ƒæƒé‡
        in_channels=3,                  # çº¯ RGB
        classes=1, 
        activation=None
    )

def load_checkpoint(path, device):
    if not os.path.exists(path):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ¨¡å‹æ–‡ä»¶ {path}")
        exit()
        
    model = build_model()
    try:
        print(f"ğŸ”„ æ­£åœ¨åŠ è½½æƒé‡: {os.path.basename(path)}")
        checkpoint = torch.load(path, map_location=device)
        # å…¼å®¹å¤„ç†: å¤„ç†å¸¦ 'state_dict' é”®æˆ–ä¸å¸¦çš„æƒ…å†µ
        state_dict = checkpoint['state_dict'] if isinstance(checkpoint, dict) and 'state_dict' in checkpoint else checkpoint
        model.load_state_dict(state_dict)
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥! è¯·æ£€æŸ¥æ¶æ„æ˜¯å¦åŒ¹é…ã€‚\né”™è¯¯ä¿¡æ¯: {e}")
        exit()
        
    model.to(device)
    model.eval()
    return model

# =============================================================
# 3. ğŸ–¼ï¸ æ•°æ®é¢„å¤„ç† (512x512)
# =============================================================
# è¿™é‡Œçš„ Resize å¿…é¡»æ˜¯ 512ï¼Œå¦åˆ™æ¨¡å‹ä¼šæŠ¥é”™æˆ–æ•ˆæœæå·®
INFERENCE_TRANSFORM = A.Compose([
    A.Resize(INPUT_SIZE, INPUT_SIZE),
    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),
    ToTensorV2(),
])

def load_mask(mask_path, target_h, target_w):
    try:
        if not os.path.exists(mask_path): return None
        mask = np.load(mask_path)
        if mask.ndim > 2: mask = np.max(mask, axis=-1)
        # ç»Ÿä¸€ç¼©æ”¾åˆ°åŸå›¾å¤§å°æ–¹ä¾¿å¯¹æ¯”
        if mask.shape[:2] != (target_h, target_w):
            mask = cv2.resize(mask.astype(np.float32), (target_w, target_h), interpolation=cv2.INTER_NEAREST)
        return mask.astype(np.float32)
    except: return None

# =============================================================
# 4. ğŸ”® é¢„æµ‹ä¸å¯è§†åŒ–æ ¸å¿ƒé€»è¾‘
# =============================================================
def predict_and_plot(model, img_path, mask_dir):
    filename = os.path.basename(img_path)
    file_id = os.path.splitext(filename)[0]
    
    # 1. è¯»å–åŸå›¾
    image = cv2.imread(img_path)
    if image is None: return
    orig_h, orig_w = image.shape[:2]
    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    # 2. å°è¯•è¯»å– Ground Truth æ©ç 
    # å…¼å®¹ä¸¤ç§è·¯å¾„: ç›´æ¥åœ¨æ–‡ä»¶å¤¹ä¸‹ æˆ– åœ¨ forged å­æ–‡ä»¶å¤¹ä¸‹
    candidates = [
        os.path.join(mask_dir, file_id + ".npy"),
        os.path.join(mask_dir, "forged", file_id + ".npy")
    ]
    gt_mask = None
    for p in candidates:
        gt_mask = load_mask(p, orig_h, orig_w)
        if gt_mask is not None: break
        
    if gt_mask is None:
        gt_mask = np.zeros((orig_h, orig_w))
        has_gt = False
    else:
        has_gt = True

    # 3. æ¨ç† (Resize -> Predict -> Resize Back)
    aug = INFERENCE_TRANSFORM(image=image_rgb)["image"]
    input_tensor = aug.unsqueeze(0).to(DEVICE) # [1, 3, 512, 512]
    
    with torch.no_grad():
        logits = model(input_tensor)
        probs = torch.sigmoid(logits)
        
    # è·å– 512x512 çš„é¢„æµ‹ç»“æœ
    pred_raw = probs[0][0].cpu().numpy()
    # è¿˜åŸå›åŸå›¾å°ºå¯¸ (æ¯”å¦‚ 1024x768)ï¼Œè¿™æ ·å¯¹æ¯”æ‰æ¸…æ™°
    pred_mask = cv2.resize(pred_raw, (orig_w, orig_h))
    
    # 4. ç»˜å›¾
    plt.figure(figsize=(16, 6))
    
    # --- åŸå›¾ ---
    plt.subplot(1, 3, 1)
    plt.imshow(image_rgb)
    plt.title(f"Input: {filename}\n({orig_w}x{orig_h})")
    plt.axis("off")
    
    # --- çœŸå®æ ‡ç­¾ (GT) ---
    plt.subplot(1, 3, 2)
    plt.imshow(image_rgb)
    if has_gt and gt_mask.sum() > 0:
        gt_overlay = np.zeros_like(image_rgb)
        gt_overlay[gt_mask > 0.5] = [0, 255, 0] # ç»¿è‰²
        plt.imshow(cv2.addWeighted(image_rgb, 0.6, gt_overlay, 0.4, 0))
        plt.title("Ground Truth (Green)")
    else:
        plt.title("Ground Truth (Not Found / Clean)")
    plt.axis("off")
    
    # --- æ¨¡å‹é¢„æµ‹ (Pred) ---
    plt.subplot(1, 3, 3)
    plt.imshow(image_rgb)
    
    # çº¢è‰²çƒ­åŠ›å›¾æ˜¾ç¤ºé¢„æµ‹
    pred_overlay = np.zeros_like(image_rgb)
    # è®¾å®šä¸€ä¸ªé˜ˆå€¼ï¼Œæ¯”å¦‚ 0.5
    threshold = 0.5
    mask_binary = pred_mask > threshold
    pred_overlay[mask_binary] = [255, 0, 0] # çº¢è‰²
    
    plt.imshow(cv2.addWeighted(image_rgb, 0.6, pred_overlay, 0.4, 0))
    
    # è®¡ç®— IoU
    iou = 0.0
    if has_gt and gt_mask.sum() > 0:
        intersection = np.logical_and(gt_mask > 0.5, mask_binary).sum()
        union = np.logical_or(gt_mask > 0.5, mask_binary).sum()
        iou = intersection / (union + 1e-6)
        
    plt.title(f"EfficientNet-B4 Prediction\nIoU: {iou:.2f}")
    plt.axis("off")
    
    plt.tight_layout()
    plt.show()

# =============================================================
# 5. ä¸»è¿è¡Œç¨‹åº
# =============================================================
if __name__ == "__main__":
    # 1. åŠ è½½æ¨¡å‹
    model = load_checkpoint(MODEL_PATH, DEVICE)
    
    # 2. è·å–å›¾ç‰‡åˆ—è¡¨
    if not os.path.exists(TEST_IMG_DIR):
        print(f"âŒ å›¾ç‰‡æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {TEST_IMG_DIR}")
    else:
        # é€’å½’æœç´¢æ‰€æœ‰å›¾ç‰‡
        all_files = []
        for root, dirs, files in os.walk(TEST_IMG_DIR):
            for f in files:
                if f.lower().endswith(('.png', '.jpg', '.jpeg', '.tif')):
                    all_files.append(os.path.join(root, f))
                    
        print(f"ğŸ“‚ åœ¨ {os.path.basename(TEST_IMG_DIR)} ä¸­æ‰¾åˆ° {len(all_files)} å¼ å›¾ç‰‡ã€‚")
        
        if len(all_files) > 0:
            # éšæœºæŠ½å– 5 å¼ è¿›è¡Œæµ‹è¯•
            selected_files = random.sample(all_files, min(5, len(all_files)))
            print("ğŸš€ å¼€å§‹é¢„æµ‹...\n")
            
            for img_path in selected_files:
                predict_and_plot(model, img_path, MASK_DIR)
        else:
            print("âŒ æ–‡ä»¶å¤¹é‡Œæ²¡æœ‰å›¾ç‰‡")